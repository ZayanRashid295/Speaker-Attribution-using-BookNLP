{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T06:25:34.947097Z",
     "start_time": "2025-04-19T06:25:25.635479Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (2.2.3)\r\n",
      "Collecting scikit-learn\r\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: numpy in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (2.2.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\r\n",
      "  Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\r\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\r\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/ali-nasir/PycharmProjects/DjangoProject2/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\r\n",
      "Using cached scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\r\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\r\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn numpy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcb8e31250067d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T06:26:42.005038Z",
     "start_time": "2025-04-19T06:26:41.895137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker Attribution Analysis Script\n",
      "----------------------------------\n",
      "Loaded ground truth with 18 quotes\n",
      "Loaded small model output with 18 quotes\n",
      "Loaded big model output with 18 quotes\n",
      "\n",
      "Accuracy Results:\n",
      "Small model accuracy: 88.89%\n",
      "Big model accuracy: 94.44%\n",
      "\n",
      "Small Model Errors (2):\n",
      "Quote 5: \"Charlotte, don't you feel, too, that we might be in London? I can hardly believe that all kinds of other things are just outside. I suppose it is one's being so tired.\"\n",
      "  True speaker: Lucy\n",
      "  Predicted: Miss Bartlett\n",
      "\n",
      "Quote 14: \"I have a view, I have a view.\"\n",
      "  True speaker: Old Man\n",
      "  Predicted: Unknown\n",
      "\n",
      "\n",
      "Big Model Errors (1):\n",
      "Quote 17: \"his name's George. He has a view too.\"\n",
      "  True speaker: Old Man\n",
      "  Predicted: Lucy\n",
      "\n",
      "\n",
      "Error Analysis by Speaker:\n",
      "Miss Bartlett: 10 quotes\n",
      "  Small model errors: 0/10 (0.00%)\n",
      "  Big model errors: 0/10 (0.00%)\n",
      "Lucy: 5 quotes\n",
      "  Small model errors: 1/5 (20.00%)\n",
      "  Big model errors: 0/5 (0.00%)\n",
      "Old Man: 3 quotes\n",
      "  Small model errors: 1/3 (33.33%)\n",
      "  Big model errors: 1/3 (33.33%)\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Speaker Attribution Analysis Script\")\n",
    "print(\"----------------------------------\")\n",
    "\n",
    "# Load ground truth data\n",
    "ground_truth = pd.read_csv(\"input/quote_info.csv\")\n",
    "print(f\"Loaded ground truth with {len(ground_truth)} quotes\")\n",
    "\n",
    "# Load model outputs\n",
    "small_model = pd.read_csv(\"output_small/novel_small.quotes\", sep=\"\\t\")\n",
    "print(f\"Loaded small model output with {len(small_model)} quotes\")\n",
    "\n",
    "big_model = pd.read_csv(\"output_big/novel_big.quotes\", sep=\"\\t\")\n",
    "print(f\"Loaded big model output with {len(big_model)} quotes\")\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(model, ground_truth):\n",
    "    correct = sum(model[\"char_id\"] == ground_truth[\"char_id\"])\n",
    "    total = len(ground_truth)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "small_accuracy = calculate_accuracy(small_model, ground_truth)\n",
    "big_accuracy = calculate_accuracy(big_model, ground_truth)\n",
    "\n",
    "print(f\"\\nAccuracy Results:\")\n",
    "print(f\"Small model accuracy: {small_accuracy:.2%}\")\n",
    "print(f\"Big model accuracy: {big_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "# Find misattributions\n",
    "def find_errors(model, ground_truth):\n",
    "    errors = []\n",
    "    for i, (_, gt_row) in enumerate(ground_truth.iterrows()):\n",
    "        model_row = model.iloc[i]\n",
    "        if gt_row[\"char_id\"] != model_row[\"char_id\"]:\n",
    "            errors.append({\n",
    "                \"quote_id\": gt_row[\"quote_id\"],\n",
    "                \"quote_text\": gt_row[\"quote_text\"],\n",
    "                \"true_speaker\": gt_row[\"speaker\"],\n",
    "                \"predicted_speaker\": model_row[\"speaker\"],\n",
    "                \"true_id\": gt_row[\"char_id\"],\n",
    "                \"predicted_id\": model_row[\"char_id\"]\n",
    "            })\n",
    "    return errors\n",
    "\n",
    "\n",
    "small_errors = find_errors(small_model, ground_truth)\n",
    "big_errors = find_errors(big_model, ground_truth)\n",
    "\n",
    "print(f\"\\nSmall Model Errors ({len(small_errors)}):\")\n",
    "for error in small_errors:\n",
    "    print(f\"Quote {error['quote_id']}: {error['quote_text']}\")\n",
    "    print(f\"  True speaker: {error['true_speaker']}\")\n",
    "    print(f\"  Predicted: {error['predicted_speaker']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nBig Model Errors ({len(big_errors)}):\")\n",
    "for error in big_errors:\n",
    "    print(f\"Quote {error['quote_id']}: {error['quote_text']}\")\n",
    "    print(f\"  True speaker: {error['true_speaker']}\")\n",
    "    print(f\"  Predicted: {error['predicted_speaker']}\")\n",
    "    print()\n",
    "\n",
    "# Error analysis by speaker\n",
    "speakers = ground_truth[\"speaker\"].unique()\n",
    "print(\"\\nError Analysis by Speaker:\")\n",
    "for speaker in speakers:\n",
    "    speaker_quotes = ground_truth[ground_truth[\"speaker\"] == speaker]\n",
    "    small_speaker_errors = sum(small_model.iloc[speaker_quotes.index][\"speaker\"] != speaker)\n",
    "    big_speaker_errors = sum(big_model.iloc[speaker_quotes.index][\"speaker\"] != speaker)\n",
    "\n",
    "    total = len(speaker_quotes)\n",
    "    print(f\"{speaker}: {total} quotes\")\n",
    "    print(f\"  Small model errors: {small_speaker_errors}/{total} ({small_speaker_errors / total:.2%})\")\n",
    "    print(f\"  Big model errors: {big_speaker_errors}/{total} ({big_speaker_errors / total:.2%})\")\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
